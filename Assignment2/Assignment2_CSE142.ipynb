{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flexible-nickname",
   "metadata": {
    "id": "flexible-nickname"
   },
   "source": [
    "\n",
    "<h1 align=\"center\"> CSE 142 Assignment 2, Fall 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-credit",
   "metadata": {
    "id": "republican-credit"
   },
   "source": [
    "\n",
    "<h2 align=\"center\"> 3 Questions, 100 pts, due: 23:59 pm, Oct 26th, 2023\n",
    "    \n",
    "    Your name:          Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-grain",
   "metadata": {
    "id": "backed-grain"
   },
   "source": [
    "## Instruction \n",
    "\n",
    "- Submit your assignments onto **Gradescope** by the due date. Upload a <code>zip</code> file containing:\n",
    "\n",
    "    (1) The saved/latest <code>.ipynb</code> file.\n",
    "\n",
    "    (2) Also save your file into a pdf version, if error appears, save an html version instead (easy to grade for written questions).\n",
    "    \n",
    "    (3) All other materials to make your <code>.ipynb</code> file runnable.\n",
    "    \n",
    "    **For assignment related questions, please reach TA or grader through Canvas/Piazza/Email.**\n",
    "    \n",
    "- This is an **individual** assignment. All help from others (from the web, books other than text, or people other than the TA or instructor) must be clearly acknowledged. \n",
    "- Most coding parts can be finished with only 1-2 lines of codes.\n",
    "- Make sure you have installed required packages: <code>scikit-learn</code>.\n",
    "- Double click to edit each markdown cell.\n",
    "\n",
    "## Objective \n",
    "\n",
    "- **Task 1:** Maximum likelihood estimation (math)\n",
    "- **Task 2:** Linear Regression (with Scikit-learn)\n",
    "- **Task 3:** Principle Component Analysis (with Scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-removal",
   "metadata": {
    "id": "obvious-removal"
   },
   "source": [
    "# Question 1 (Maximum likelihood estimation and Posterior, 20 pts) \n",
    "\n",
    "Assume we have a coin that has some unknown probability $h$ of coming up heads (and probability $1-h$ of coming up tails). If the coin is flipped five times getting three heads and two tails ($\\mathbf{HHHTT}$) then:\n",
    "\n",
    "(a -- 10pts) What is the maximum likelihood estimate for $h$?\n",
    "\n",
    "(b -- 10pts) Assume that (before flipping the coin) we have a prior density $p(h)$ for the various values of $h\\in [0,1]$. Give the formula for the posterior probability density $p(h \\mid \\mathbf{HHHTT})$ as a function of the prior $p(h)$.\n",
    "\n",
    "For Question 1(b), the solution is acceptable if the formula contains an integral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-racing",
   "metadata": {
    "id": "diagnostic-racing"
   },
   "source": [
    "**Solution (a)**:\n",
    "\n",
    "**Solution (b)**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338202f8",
   "metadata": {
    "id": "338202f8"
   },
   "source": [
    "**If you are not familair with Latex, you may attach a figure/screen-shoot and display the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-compound",
   "metadata": {
    "id": "handy-compound"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Replace the figure name\n",
    "# Image(filename='sample.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-musical",
   "metadata": {
    "id": "laden-musical"
   },
   "source": [
    "# Question 2 (Linear Regression, 40 pts)\n",
    "In this question, you will be using **Scikit-learn** to empirically apply the Linear Regression model. We will adopt an advertisement dataset **Advertising.csv** from Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-horse",
   "metadata": {
    "id": "amazing-horse"
   },
   "source": [
    "### Reading data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitted-stranger",
   "metadata": {
    "id": "fitted-stranger"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset you will be working on\n",
    "# The dataframe loaded with pandas is named as data\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)  # Modify your data path accordingly.\n",
    "\n",
    "# Take a look at the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fe4682",
   "metadata": {
    "id": "29fe4682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14802d5",
   "metadata": {
    "id": "f14802d5"
   },
   "source": [
    "### Features and responses\n",
    "\n",
    "What are the features?\n",
    "- **TV:** advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "- **Radio:** advertising dollars spent on Radio\n",
    "- **Newspaper:** advertising dollars spent on Newspaper\n",
    "\n",
    "What is the response?\n",
    "- **Sales:** sales of a single product in a given market (in thousands of items)\n",
    "\n",
    "What else do we know?\n",
    "- There are 200 **observations**, and each observation (each row) is a single market.\n",
    "- **Your main task**: predict the sales of a single product in a given market.\n",
    "- Since the response variable is continuous, this is a **regression** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242cb7c5",
   "metadata": {
    "id": "242cb7c5"
   },
   "source": [
    "### Linear regression\n",
    "\n",
    "**Pros:** fast, no tuning required, highly interpretable\n",
    "\n",
    "**Cons:** adopting the linear regression is unlikely to always generate the best predictive accuracy, since Linear Regression presumes a linear relationship between the features and response. This assumption may not always make sense. (But if one can _transform_ the features so that do have a linear relationship, sometimes progress can be made, for example by taking logs.)\n",
    "\n",
    "**Expression:**\n",
    "\n",
    "- $y$: the response\n",
    "- $\\beta_0$: the intercept\n",
    "- $\\beta_1$: the coefficient for $x_1$ (the first feature)\n",
    "- $\\beta_i$ is the coefficient for $x_i$ (the ith feature, $i\\in \\{1, 2, ..., n\\}$)\n",
    "\n",
    "For this regression task:\n",
    "\n",
    "$\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV} + \\beta_2 \\times \\text{Radio} + \\beta_3 \\times \\text{Newspaper}$\n",
    "\n",
    "The $\\beta$ values ($\\beta=[\\beta_0, \\beta_1, \\beta_2, \\beta_3]$) are called the **model coefficients**. These values are \"learned\" during the model fitting step using the \"least squares\" criterion. Then, we can make use of the fitted model to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638cce38",
   "metadata": {
    "id": "638cce38"
   },
   "source": [
    "### Prepare the dataset for training use\n",
    "\n",
    "- Scikit-learn expects X (feature matrix) and y (response vector) to be NumPy arrays.\n",
    "- Pandas is built on top of NumPy, and exposes numpy methods. Thus, X can be a pandas DataFrame, y can be a pandas Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7df1cd",
   "metadata": {
    "id": "3c7df1cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the feature X\n",
    "X = data[['TV', 'Radio', 'Newspaper']]\n",
    "\n",
    "# check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee92b344",
   "metadata": {
    "id": "ee92b344",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the response Y\n",
    "y = data['Sales']\n",
    "# check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-entrepreneur",
   "metadata": {
    "id": "speaking-entrepreneur"
   },
   "source": [
    "## Question 2.1 (Split the dataset into train and test parts, 5 pts)\n",
    "\n",
    "For features $X$ and response $y$, use **sklearn** to perform the the splitting of dataset: $80\\%$ for train data, $20\\%$ for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finished-gateway",
   "metadata": {
    "id": "finished-gateway"
   },
   "outputs": [],
   "source": [
    "################# Your answer for Question 2.1   #################\n",
    "\n",
    "\n",
    "\n",
    "################# Your code above #################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc75318",
   "metadata": {
    "id": "9bc75318"
   },
   "source": [
    "Double check the shape of train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1f462c",
   "metadata": {
    "id": "7f1f462c",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\デスクトップ\\UCSC Studies\\Machine Learning\\Assignment2\\Assignment2_CSE142.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/UCSC%20Studies/Machine%20Learning/Assignment2/Assignment2_CSE142.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# default split is 80% for training and 20% for testing\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/UCSC%20Studies/Machine%20Learning/Assignment2/Assignment2_CSE142.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/UCSC%20Studies/Machine%20Learning/Assignment2/Assignment2_CSE142.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(y_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/UCSC%20Studies/Machine%20Learning/Assignment2/Assignment2_CSE142.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(X_test\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# default split is 80% for training and 20% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a55748",
   "metadata": {
    "id": "b3a55748"
   },
   "source": [
    "## Question 2.2 (Train a Linear regression model via Scikit-learn, 10 pts)\n",
    "\n",
    "Assume you model is named as **model**, and you train the linear regression model to fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80a69a",
   "metadata": {
    "id": "ad80a69a"
   },
   "outputs": [],
   "source": [
    "################# Your answer for Question 2.2   #################\n",
    "# Name your linear regression model as 'model', so proceeding cells won't run into errors.\n",
    "\n",
    "\n",
    "################# Your code above #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ddd28d",
   "metadata": {
    "id": "46ddd28d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at your model coefficients\n",
    "import numpy as np\n",
    "print(np.round(model.intercept_, 4))\n",
    "print([np.round(val, 4) for val in model.coef_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4bcfe",
   "metadata": {
    "id": "32d4bcfe"
   },
   "outputs": [],
   "source": [
    "# Match the feature names with the trained coefficients\n",
    "list(zip(data.columns[:3].tolist(), model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fa7a7",
   "metadata": {
    "id": "732fa7a7"
   },
   "source": [
    "## Question 2.3 (Interpreting model coefficients, 10 pts)\n",
    "\n",
    "The coefficients of each feature are printed above. \n",
    "\n",
    "### Your tasks:\n",
    "\n",
    "- What is the trained linear regression model? \n",
    "\n",
    "- **(replace $\\beta_i$ below with the trained coefficients, reserve four decimal places, 5 pts)**\n",
    "\n",
    "$$\\text{Sales} = \\beta_0 + \\beta_1 \\times \\text{TV} + \\beta_2 \\times \\text{Radio} + \\beta_3 \\times \\text{Newspaper}$$\n",
    "\n",
    "- **(Open) question (5 pts)**: how do you interpret the coefficient of **TV** ($\\beta_1$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3027a9",
   "metadata": {
    "id": "4d3027a9"
   },
   "source": [
    "### Your solution for Question 2.3: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f14c2",
   "metadata": {
    "id": "198f14c2"
   },
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b4ded5",
   "metadata": {
    "id": "86b4ded5"
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "# Print the test accuracy score from your trained linear regression model\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7824c",
   "metadata": {
    "id": "e5a7824c"
   },
   "source": [
    "## Model evaluation metrics for regression\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. Instead, we need evaluation metrics designed for comparing continuous values.  (Since predictions would hardly ever exactly match the measured quantities.)\n",
    "\n",
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) is a popular evaluation metric for regression, which is defined as the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af174ff",
   "metadata": {
    "id": "5af174ff"
   },
   "source": [
    "## Question 2.4 (Evaluate your predictions on test features with RMSE metric, 5 pts)\n",
    "\n",
    "Hint: you may calculate MSE using scikit-learn, but RMSE is a little bit different from MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237b67a",
   "metadata": {
    "id": "e237b67a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "################# Your answer for Question 2.4   #################\n",
    "\n",
    "\n",
    "\n",
    "################# Your code above #################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff366bd5",
   "metadata": {
    "id": "ff366bd5"
   },
   "source": [
    "## Question 2.5 (Does the feature 'Newspaper' help? 10 pts)\n",
    "\n",
    "Does the feature **Newspaper** contribute or impair the model prediction? Now repeat previous procedure: \n",
    "\n",
    "- For features $X$, only select **TV** and **Radio**; response $y$ is unchanged.\n",
    "\n",
    "- Split the dataset as what you have done before.\n",
    "\n",
    "- Fit/Train the model on the train data.\n",
    "\n",
    "- Make predictions on the test data.\n",
    "\n",
    "- Compute the RMSE of the predictions on the test data.\n",
    "\n",
    "- **Show your observations!**\n",
    "\n",
    "**Reminder:** if you use <code>random_state</code> while splitting the dataset, make sure the value of <code>random_state</code> is the same for the two splits. So that the test data only differs in the column of **Newspaper**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a028e0e",
   "metadata": {
    "id": "4a028e0e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# Your answer for Question 2.5   #################\n",
    "\n",
    "\n",
    "\n",
    "################# Your code above #################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d93ac4",
   "metadata": {
    "id": "75d93ac4"
   },
   "source": [
    "### Your observations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-webster",
   "metadata": {
    "id": "demonstrated-webster"
   },
   "source": [
    "# Question 3 (PCA, 40 pts)\n",
    "\n",
    "In this question, we will explore how PCA helps with reducing the dimensionality through scikit-learn. We will adopt a simple digits dataset contained in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db4f94",
   "metadata": {
    "id": "d6db4f94"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e6e0f",
   "metadata": {
    "id": "146e6e0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data_digit = load_digits()\n",
    "data_digit.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce797c",
   "metadata": {
    "id": "87ce797c"
   },
   "source": [
    "As you have seen above, there are 1797 rows and 64 columns in this dataset. Each row denotes the pixel values of an image. Since each image is 8*8 (in pixel), the dimension of each feature is 64. Let's take a look at a few images contained in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc008c",
   "metadata": {
    "id": "42bc008c"
   },
   "outputs": [],
   "source": [
    "# A help function to display images with labels\n",
    "def display_digits(imgs):\n",
    "    h = 3\n",
    "    w = 5\n",
    "    fig, axes = plt.subplots(h, w)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if imgs.shape[1] == 64:\n",
    "                axes[i, j].imshow(imgs[i * w + j].reshape(8, 8))\n",
    "            else:\n",
    "                axes[i, j].imshow(imgs[i * w + j])\n",
    "            axes[i, j].axis('off')\n",
    "            axes[i, j].set_title(f'label {data_digit.target[i * w + j]}')\n",
    "# Take a look at a few examples\n",
    "display_digits(data_digit.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8616b756",
   "metadata": {
    "id": "8616b756"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcbbb752",
   "metadata": {
    "id": "dcbbb752"
   },
   "source": [
    "**PCA** finds uncorrelated orthogonal axes (principal components) in a high dimensional space (i.e., 64) to project the feature onto principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a0efa",
   "metadata": {
    "id": "126a0efa"
   },
   "source": [
    "## Question 3.1 (PCA and dimensionality deduction with Scikit-learn, 10 pts)\n",
    "\n",
    "In this question, you may use the implementation of PCA from scikit-learn, as imported below. Detailed explanations of parameters settings are available in this [link](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "### Your task in this question:\n",
    "\n",
    "Fit the model with feature X (**data_digit.data** for this dataset) and apply the dimensionality reduction on X, keep 2 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea938f",
   "metadata": {
    "id": "23ea938f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "################# Your answer for Question 3.1   #################\n",
    "\n",
    "# name the transformed (dimension reduced) feature as projected\n",
    "projected = \n",
    "################# Complete the code above #################\n",
    "\n",
    "\n",
    "# The code below checks whether the feature dimension 64 is reduced to 2.\n",
    "print(data_digit.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33b60f",
   "metadata": {
    "id": "1c33b60f"
   },
   "source": [
    "With the reduced dimension of features, we can now visualize the projected/reduced features in a 2-dimension plot as below. There are hardly any overlaps between digit 0 and any other digits. While in the central area of the figure, features are not well separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8729b8a4",
   "metadata": {
    "id": "8729b8a4"
   },
   "outputs": [],
   "source": [
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=data_digit.target, edgecolor='none', alpha=0.7,\n",
    "            cmap=plt.cm.get_cmap('Paired', 10))\n",
    "plt.xlabel('1st Component')\n",
    "plt.ylabel('2nd Component')\n",
    "plt.colorbar()\n",
    "plt.figure(figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c6f95",
   "metadata": {
    "id": "323c6f95"
   },
   "source": [
    "## Question 3.2 (How many components do we need? 15 pts)\n",
    "\n",
    "In practice, suppose you are given a high-dimension dataset, and you are interested in performing a dimension reduciton with PCA. How many conponents do we need? One method is to look at the distribution of the explained variance ratio w.r.t. each component.\n",
    "\n",
    "In this question, you may use the function <code>explained_variance_ratio</code> in **pca** (with scikit-learn) to address this question. Detailed explanations of parameters settings are available in this [link](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "### Your task in this question:\n",
    "\n",
    "Print the ratio of variance explained by each of the selected components;\n",
    "\n",
    "Visualize with matplotlib or seaborn (x axis: $i-th$ component; y axis: the corresponding ratio of explained variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cef6f0",
   "metadata": {
    "id": "51cef6f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# Your answer for Question 3.2   #################\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('The $i-$th component')\n",
    "plt.ylabel('Ratio of explained variance')\n",
    "################# Complete the code above #################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6e5b0f",
   "metadata": {
    "id": "4b6e5b0f"
   },
   "source": [
    "### How to obtain eigen values and vectors from sklearn PCA\n",
    "\n",
    "- Eigen values -- <code>your-PCA-model\\.explained\\_variance\\_</code>\n",
    "\n",
    "- Eigen vectors -- <code>your-PCA-model.components_ </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991a57c",
   "metadata": {
    "id": "c991a57c"
   },
   "source": [
    "### Eigen vectors (Eigen digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc6cd2",
   "metadata": {
    "id": "f3dc6cd2"
   },
   "outputs": [],
   "source": [
    "# Default # of components is the dimension of feature space \n",
    "pca = PCA()\n",
    "pca.fit(data_digit.data)\n",
    "h = 6\n",
    "w = 12\n",
    "fig, axes = plt.subplots(h, w)\n",
    "fig.set_size_inches(12, 7)\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        idx = i * w + j\n",
    "        if idx > 63:\n",
    "            axes[i, j].axis('off')\n",
    "        else:\n",
    "            axes[i, j].imshow(pca.components_[idx].reshape(8, 8))\n",
    "            axes[i, j].axis('off')\n",
    "            axes[i, j].set_title(f'{idx + 1}-th')\n",
    "fig.suptitle('The eigen vector of each component')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c3acb",
   "metadata": {
    "id": "9a5c3acb"
   },
   "source": [
    "## Question 3.3 What are your observations from the visualized eigen vectors? (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae86cd",
   "metadata": {
    "id": "2cae86cd"
   },
   "source": [
    "### Your solutions for Question 3.3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eba613",
   "metadata": {
    "id": "73eba613"
   },
   "source": [
    "### Feature reconstruction:\n",
    "\n",
    "Suppose you only want to preserve $80\\%$ variance after applying PCA for the dimension reduction, due to storage issues, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4145f2",
   "metadata": {
    "id": "5b4145f2"
   },
   "outputs": [],
   "source": [
    "# Use pca from sklearn to fit on the feature space\n",
    "pca_08 = PCA(0.8).fit(data_digit.data)\n",
    "\n",
    "# Reconstruct \n",
    "lower_dimension = pca_08.fit_transform(data_digit.data)\n",
    "reconstructed = pca_08.inverse_transform(lower_dimension)\n",
    "\n",
    "# Display the reconstructed images (with a much lower dimension)\n",
    "display_digits(reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f51159",
   "metadata": {
    "id": "81f51159"
   },
   "source": [
    "Assume now you are given only a set of perturbed images (with some random noise). As shown below, the figures become much more difficult to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe13cf",
   "metadata": {
    "id": "d8fe13cf"
   },
   "outputs": [],
   "source": [
    "# Apply random noise on clean images\n",
    "noisy_imgs = np.random.normal(data_digit.data, 5)\n",
    "# Display the noisy images\n",
    "display_digits(noisy_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092bb8b",
   "metadata": {
    "id": "3092bb8b"
   },
   "source": [
    "## Question 3.4 Does PCA mitigate the random noise? (10 pts)\n",
    "\n",
    "### Your tasks:\n",
    "\n",
    "- Perform feature reconstruction on <code>noisy\\_imgs</code> (preserving $80\\%$ variance after applying PCA for the dimension reduction)\n",
    "\n",
    "- Explain your understandings on why PCA reconstructs cleaner images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55abf3b",
   "metadata": {
    "id": "f55abf3b"
   },
   "outputs": [],
   "source": [
    "################# Your answer for Question 3.4   #################\n",
    "\n",
    "\n",
    "\n",
    "# name the reconstructed images from noisy images as 'reconstructed_noise'\n",
    "reconstructed_noise = \n",
    "# Display the reconstructed images\n",
    "display_digits(reconstructed_noise) \n",
    "################# Complete the code above #################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d38b71",
   "metadata": {
    "id": "74d38b71"
   },
   "source": [
    "### Your written answers for Question 3.4:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
